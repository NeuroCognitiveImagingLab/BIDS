{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c88bcae9-2be4-42d0-965f-c37d3a0f1523",
   "metadata": {},
   "source": [
    "# EEG-ERP Preprocessing \n",
    "## Batch script\n",
    "\n",
    "This script will run on all subjects in `rawdata`. Steps performed include:\n",
    "- filtering\n",
    "- epoching\n",
    "- mark bad segments of data (trials/channels) using AutoReject\n",
    "- pass the marked data to ICA\n",
    "- auto-idenitfy and remove ocular indepdent components \n",
    "- apply ICA to epoched data\n",
    "- apply AutoReject to ICA-cleaned data\n",
    "- rereference\n",
    "- export clean epochs to `.fif` file in `derivatives/erp_preprocessing`\n",
    "- save an MNE report with details/vizualizations of the above steps in `derivatives/erp_preprocessing/logs`\n",
    "\n",
    "Most parameters that you would want to change are read from `config.yml`. \n",
    "\n",
    "It is recommended that you not apply any baseline correction at this stage (and the defult config.yml file reflects this). Baseline correction can be applied in subsequent scripts, but doing baseline correction here precludes later using baseline regression.\n",
    "\n",
    "Bad channels and non-ocular independent components can be manually identified after this script is run the first time. These can be stored in additional config files saved in `rawdata`, and then this script can be re-run to have those excluded. In an ideal world with reasnably clean data this should not be necessary, but e.g., if there are broken electrodes, EGI data, data from children, etc. it may be necessary.\n",
    "\n",
    "---\n",
    "Copyright 2023 [Aaron J Newman](https://github.com/aaronjnewman), [NeuroCognitive Imaging Lab](http://ncil.science), [Dalhousie University](https://dal.ca)\n",
    "\n",
    "Released under the [The 3-Clause BSD License](https://opensource.org/licenses/BSD-3-Clause)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db9a01-dd5f-4cc7-8607-2fc0be02abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as op\n",
    "from os import remove\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "import mne\n",
    "mne.set_log_level('error')\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from scipy.stats import zscore\n",
    "from autoreject import Ransac, get_rejection_threshold, AutoReject\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b8946-693c-4056-97e0-51a3e4cf37ce",
   "metadata": {},
   "source": [
    "## Read Parameters from config.yml\n",
    "\n",
    "Will import study-level parameters from `config.yml` in `bids_root`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2575b-4e47-4225-b250-dea80acf202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shouldn't change if you run this script from its default location in code/import\n",
    "bids_root = '../..'\n",
    "\n",
    "cfg_file = op.join(bids_root, 'config.yml')\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "study_name = config['study_name']\n",
    "task = config['task']\n",
    "data_type = config['data_type']\n",
    "eog = {k: v for d in config['eog'] for k, v in d.items()}\n",
    "drop_ch = config['drop_ch']            \n",
    "montage_fname = config['montage_fname']\n",
    "event_id = {k: v.pop() for d in config['events'] for k, v in d.items()}\n",
    "\n",
    "# fix per changes to config\n",
    "n_jobs = config['preprocessing_settings']['n_jobs']\n",
    "filt_p = {k: v for d in config['preprocessing_settings']['filter'] for k, v in d.items()}\n",
    "ica_p = {k: v for d in config['preprocessing_settings']['ica'] for k, v in d.items()}\n",
    "epoch_p = {k: v for d in config['preprocessing_settings']['epoch'] for k, v in d.items()}\n",
    "reject = {k:eval(v)  for i in epoch_p['reject'] for k, v in i.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011eb68-416b-403b-827a-14f9ff378b78",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2b4fc-7c40-4a7d-b529-717355fd03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = op.join(bids_root, 'rawdata')\n",
    "\n",
    "derivatives_path = op.join(bids_root, 'derivatives', 'erp_preprocessing_rej')\n",
    "if Path(derivatives_path).exists() == False:\n",
    "    Path(derivatives_path).mkdir(parents=True)\n",
    "\n",
    "report_path = op.join(derivatives_path, 'logs')\n",
    "if Path(report_path).exists() == False:\n",
    "    Path(report_path).mkdir(parents=True)\n",
    "\n",
    "\n",
    "epochs_suffix = '-epo.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134bcd2-1736-40bf-9514-7baa20e945c2",
   "metadata": {},
   "source": [
    "### Subject list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d4d45-eebc-4f62-9902-cd5dc6a47dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sub-'\n",
    "subjects = sorted([s[-7:] for s in glob(raw_path + '/' + prefix + '*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafb8ae-e633-412e-824a-d1b7823be04e",
   "metadata": {},
   "source": [
    "## Read manually-marked independent components\n",
    "Run this script once, inspect ICs, make decisions about whether any additional ICs should be added, or any automatically-removed ICs should be included.\n",
    "\n",
    "Additional ICs to remove were selected based on:\n",
    "- participants for whom more than 15% of trials were removred by AutoReject after ICA correct\n",
    "- participants for whom the average across all trials and all electrodes did not show a clear pattern of P1-N1-P2 components\n",
    "- for such participants, the scalp map and details of each IC were visuall inspected. Components were removed if they were\n",
    "    - focal at a single electrode, or a very low number of electrodes\n",
    "    - focal at the edges of the electrode montage\n",
    "    - present on a low number of trials\n",
    "    - showed no systematic pattern across trials that was time-locked to stimulus onset\n",
    "    \n",
    "ICs to add (un-remove) were selected based on:\n",
    "- IC shows clear and consistent temporal dependency on stimulus onset\n",
    "- IC appears to contain P1-N1-P2 complex, or part thereof\n",
    "- IC has broad scalp distribution across many electrodes, characteristic of ERP component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a3942-be6b-408e-bb2c-9d881ebe15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = op.join(raw_path + '/participants_manual_IC.yml')\n",
    "with open(cfg_file, 'r') as f:\n",
    "    ica_manual = yaml.load(f, Loader=Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f9344-3bcc-49eb-b322-c22bdecb0fce",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532f7d5-4e01-4216-9135-ce2bedec277c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rej_log_list = []\n",
    "\n",
    "for subject in subjects:\n",
    "    start_time = time()\n",
    "    print('\\n-------------------------')\n",
    "    print('-------- ' + subject + ' --------')\n",
    "    print('-------------------------')\n",
    "\n",
    "    report = mne.Report(subject=subject, \n",
    "                        title=study_name + ' preprocessing: ' + subject,\n",
    "                        verbose='WARNING')\n",
    "\n",
    "    ### subject-specific paths\n",
    "    in_path = BIDSPath(root=raw_path, \n",
    "                       subject=subject[-3:], \n",
    "                       datatype=data_type,\n",
    "                       task=task\n",
    "                      )    \n",
    "\n",
    "    ### Import data\n",
    "    raw = read_raw_bids(in_path)\n",
    "    \n",
    "    # manually-flagged bad channels\n",
    "    # raw.info['bads'] = bad_ch[subject]\n",
    "    \n",
    "    # drop useless channels that mess with topomaps\n",
    "    raw.drop_channels(drop_ch)\n",
    "\n",
    "    # Create bipolar EOG channels\n",
    "    raw = mne.set_bipolar_reference(raw.load_data(), \n",
    "                                    anode=[e[0] for e in eog.values()],\n",
    "                                    cathode=[e[1] for e in eog.values()],\n",
    "                                    ch_name=list(eog.keys()),\n",
    "                                    ch_info=[{'kind':202} for i in range(len(eog.keys()))]\n",
    "                                   )    \n",
    "    \n",
    "    ### Filtering\n",
    "    # channel selection\n",
    "    picks = mne.pick_types(raw.info, \n",
    "                           eeg=True,\n",
    "                           eog=True\n",
    "                          )\n",
    "    \n",
    "    ## Filter for ICA  \n",
    "    raw_ica = raw.copy().filter(filt_p['l_freq_ica'], filt_p['h_freq'],\n",
    "                                picks=picks,\n",
    "                                n_jobs=n_jobs\n",
    "                               )\n",
    "\n",
    "    ## Filter for final\n",
    "    raw.filter(filt_p['l_freq'], filt_p['h_freq'],\n",
    "               picks=picks,\n",
    "               n_jobs=n_jobs\n",
    "              )\n",
    "    \n",
    "    ## Add raw to report\n",
    "    report.add_raw(raw=raw, \n",
    "               psd=True, butterfly=True, \n",
    "               title='Raw data, bandpass filtered ' + str(filt_p['l_freq']) + 'â€“' + str(filt_p['h_freq'])\n",
    "              )\n",
    "\n",
    "    ### Read events\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    event_dict_new = {}\n",
    "    for key, value in event_dict.items():\n",
    "        if key in event_id.keys():\n",
    "            # rename events of experimental interest\n",
    "            event_dict_new[event_id[key]] = value\n",
    "        # else:\n",
    "        #     # keep other events to create more epochs for ICA to fit on\n",
    "        #     event_dict_new[key] = value                       \n",
    "    \n",
    "    ## Add events to report\n",
    "    report.add_events(events, event_id=event_dict_new, \n",
    "                      sfreq=raw.info['sfreq'],\n",
    "                      title='Events'\n",
    "                     )\n",
    "    \n",
    "    ### Epoch data filtered for ICA\n",
    "    epochs_ica = mne.Epochs(raw_ica,\n",
    "                            events, event_dict_new,\n",
    "                            epoch_p['tmin'], epoch_p['tmax'],\n",
    "                            baseline=epoch_p['baseline'], detrend=epoch_p['detrend'],\n",
    "                            reject=None, \n",
    "                            flat=epoch_p['flat'],\n",
    "                            preload=True\n",
    "                           )\n",
    "\n",
    "    \n",
    "    # use AutoReject to remove bad epochs, repair sensors and return clean epochs.\n",
    "    ar = AutoReject(n_interpolate=[8, 16, 32, 64, 96],\n",
    "                    random_state=ica_p['ica_random_state'],\n",
    "                    picks=mne.pick_types(epochs_ica.info, eeg=True, eog=False),\n",
    "                    n_jobs=n_jobs, \n",
    "                    verbose=False\n",
    "                   )\n",
    "    ar.fit(epochs_ica)\n",
    "    # if subject == 'sub-045':\n",
    "    #     ar.transform(epochs_ica)\n",
    "    print('n_interpolate = ' +  str(ar.n_interpolate_['eeg']))\n",
    "    reject_log = ar.get_reject_log(epochs_ica)\n",
    "    fig = reject_log.plot('horizontal', show=False);\n",
    "    report.add_figure(fig=fig, title='AutoReject log')\n",
    "\n",
    "    ### Fit ICA\n",
    "    ica = mne.preprocessing.ICA(method='fastica',\n",
    "                                n_components=ica_p['n_components'],\n",
    "                                random_state=ica_p['ica_random_state'],\n",
    "                                max_iter='auto')\n",
    "    \n",
    "    ica.fit(epochs_ica[~reject_log.bad_epochs],  # added [~reject_log.bad_epochs] for AutoReject\n",
    "            decim=3, \n",
    "            picks=['eeg']\n",
    "            );\n",
    "\n",
    "    # Identify ocular ICs\n",
    "    # The default *z* threshold doesn't work for\n",
    "    # all subjects. This routine starts with the default z (from config) and steps down\n",
    "    # until at least n_max_eog EOG components are identified.\n",
    "    # The limitations of this are that it assumes there will always be at least n_max_eog EOG\n",
    "    # components (blinks are always present, but horizontal movements are not\n",
    "    # always present), and may not work if there are > 3 components, if the\n",
    "    # score of the third is > `z_step` less than the score of the second.\n",
    "    # In practice, many of these components (with EGI data) may not be ocular, but are (hopefully) not EEG.\n",
    "    # Be sure to check the reports and confirm no ERP components are rejected!\n",
    "\n",
    "    ica.exclude = []\n",
    "    num_excl = 0\n",
    "    z_thresh = ica_p['ica_zthresh'] \n",
    "    z_step = ica_p['ica_zstep']\n",
    "\n",
    "    while num_excl < ica_p['n_max_eog']:\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(epochs_ica, threshold=z_thresh)\n",
    "        num_excl = len(eog_indices)\n",
    "        z_thresh -= z_step # won't impact things if num_excl is â‰¥Â n_max_eog \n",
    "\n",
    "    ica.exclude = eog_indices\n",
    "    z_thresh_final = round(z_thresh + z_step, 2)\n",
    "\n",
    "    # Manual removal/re-addition of ICs based on visual inspection\n",
    "    if subject in ica_manual:\n",
    "        if 'add_ics' in ica_manual[subject]:\n",
    "            for ic in ica_manual[subject]['add_ics']:\n",
    "                ica.exclude.append(ic)\n",
    "        if 'rm_ics' in ica_manual[subject]:\n",
    "            for ic in ica_manual[subject]['rm_ics']:\n",
    "                ica.exclude.remove(ic)         \n",
    "\n",
    "    # Create average of EOG events\n",
    "    eog_evoked = mne.preprocessing.create_eog_epochs(raw_ica).average().apply_baseline(baseline=(None, epoch_p['tmin']))\n",
    "\n",
    "    ## Add ICA to report\n",
    "    report.add_ica(ica=ica, title='ICA', inst=epochs_ica,\n",
    "                   eog_evoked=eog_evoked, \n",
    "                   eog_scores=eog_scores,\n",
    "                   n_jobs=n_jobs\n",
    "                  )\n",
    "    \n",
    "    ### Segment filtered raw data into epochs for final analysis\n",
    "    epochs = mne.Epochs(raw,\n",
    "                        events, event_dict_new,\n",
    "                        epoch_p['tmin'], epoch_p['tmax'],\n",
    "                        baseline=epoch_p['baseline'], detrend=epoch_p['detrend'],\n",
    "                        reject=reject, \n",
    "                        flat=epoch_p['flat'],\n",
    "                        preload=True\n",
    "                       )\n",
    "\n",
    "    ### Apply ICA correction to epochs\n",
    "    ica.apply(epochs)\n",
    "    \n",
    "\n",
    "    ### Apply AutoReject to further clean epochs\n",
    "    ar = AutoReject(n_interpolate=[8, 16, 32, 64, 96],\n",
    "                    random_state=ica_p['ica_random_state'],\n",
    "                    picks=mne.pick_types(epochs_ica.info, eeg=True, eog=False),\n",
    "                    n_jobs=n_jobs, \n",
    "                    verbose=False\n",
    "                   )\n",
    "    epochs_clean, reject_log = ar.fit_transform(epochs, return_log=True)\n",
    "    fig = reject_log.plot('horizontal', show=False)\n",
    "    report.add_figure(fig=fig, title='AutoReject log')\n",
    "\n",
    "    ### Re-reference, now that channels are cleaned\n",
    "    epochs_clean.set_eeg_reference(ref_channels='average');\n",
    "    \n",
    "    ### Save cleaned epochs\n",
    "    out_path = BIDSPath(root=derivatives_path, \n",
    "                       subject=subject[-3:], \n",
    "                       datatype=data_type,\n",
    "                       task=task\n",
    "                      )    \n",
    "    # remove old fif file if it exists, and update bids_path\n",
    "    if str(out_path.fpath)[-len(epochs_suffix):] == epochs_suffix:\n",
    "        remove(out_path.fpath)\n",
    "        out_path = BIDSPath(root=derivatives_path, \n",
    "                   subject=subject[-3:], \n",
    "                   datatype=data_type,\n",
    "                   task=task\n",
    "                  )    \n",
    "    # save the file\n",
    "    epochs_clean.save(str(out_path.fpath) + epochs_suffix, \n",
    "                      overwrite=True)\n",
    "\n",
    "    # add epochs to report\n",
    "    report.add_epochs(epochs_clean,  \n",
    "                      title='Epochs'\n",
    "                     )\n",
    "    ### Save plot of average across all trials\n",
    "    fig = epochs_clean.copy().average().plot(spatial_colors=True, \n",
    "                                      show=False);\n",
    "    \n",
    "    # add figures to report\n",
    "    report.add_figure(fig=fig, title='Grand average over all epochs')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Add plots of average of each condition\n",
    "    for condition in event_id.values():\n",
    "        fig = epochs_clean[condition].copy().average().plot(spatial_colors=True, \n",
    "                                                            show=False);\n",
    "        report.add_figure(fig=fig, title=condition)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    proc_time = time() - start_time\n",
    "    print('Total processing time: ', proc_time)\n",
    "\n",
    "    ### Report on how much was rejected\n",
    "    rm_epochs = epochs.selection.shape[0] - epochs_clean.selection.shape[0]\n",
    "    pct_epochs = rm_epochs / epochs.selection.shape[0] * 100   \n",
    "    rej_log_list.append(pd.DataFrame({'id':subject, \n",
    "                                      'cpu_time':proc_time,\n",
    "                                      'ntrials_rej':rm_epochs,\n",
    "                                      '%t_rej':round(pct_epochs, 2),\n",
    "                                      'ic_rm':len(ica.exclude),\n",
    "                                      'n_interp':str(ar.n_interpolate_['eeg'])\n",
    "                                     }, index=[0]\n",
    "                                    )\n",
    "                       )\n",
    "\n",
    "    # Save report to file\n",
    "    report_name = report_path + '/' + subject + '.html'\n",
    "    report.save(report_name, overwrite=True)\n",
    "    \n",
    "# Collate report logs\n",
    "rej_log = pd.concat(rej_log_list)\n",
    "rej_log.to_csv(report_path + '/rejection_log_all_Ss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4af61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "760055932674735d287fd612619c18ffc3840c7c49c197eeb438d57975a1e213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

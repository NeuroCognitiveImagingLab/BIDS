{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b50dd02b-7e41-4967-ac15-10b85c5048a6",
   "metadata": {},
   "source": [
    "# Plot scatterplots + regression line relating ERP to behavioural data\n",
    "\n",
    "---\n",
    "Copyright 2022 [Aaron J Newman](https://github.com/aaronjnewman), [NeuroCognitive Imaging Lab](http://ncil.science), [Dalhousie University](https://dal.ca)\n",
    "\n",
    "Released under the [The 3-Clause BSD License](https://opensource.org/licenses/BSD-3-Clause)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46491de",
   "metadata": {},
   "source": [
    "## Which component to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf646338",
   "metadata": {},
   "outputs": [],
   "source": [
    "component = 'n170'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8698d3f-2f47-4c04-a973-cce3d1a03249",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80ca04-b635-43b6-919b-b3b8b681b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyarrow.feather as feather\n",
    "from scipy.stats import zscore\n",
    "import os.path as op\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "import mne\n",
    "mne.set_log_level(verbose='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d195c1c",
   "metadata": {},
   "source": [
    "## Read Parameters from config.yml\n",
    "\n",
    "Will import study-level parameters from `config.yml` in `bids_root`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shouldn't change if you run this script from its default location in code/import\n",
    "bids_root = '../..'\n",
    "\n",
    "cfg_file = op.join(bids_root, 'config.yml')\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "study_name = config['Study']['Name']\n",
    "study_name = config['Study']['TaskName']\n",
    "data_type = config['data_type']\n",
    "eog = {k: v for d in config['eog'] for k, v in d.items()}\n",
    "montage_fname = config['montage_fname']\n",
    "event_id = {k: v.pop() for d in config['events'] for k, v in d.items()}\n",
    "\n",
    "n_jobs = config['Preprocessing']['n_jobs']\n",
    "\n",
    "component_p = config['components'][component]\n",
    "component_meas = component_p['component_meas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e87ae",
   "metadata": {},
   "source": [
    "## Time windows of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the total length of the epoch \n",
    "# this can be less than what is in the input files; will use the crop function\n",
    "t_min = float(component_p['t_min'])\n",
    "t_max =  float(component_p['t_max'])\n",
    "baseline = eval(component_p['baseline'])\n",
    "\n",
    "# value obtained from butterfly plots visual inspection and added to config.yml\n",
    "# peak_lat = {k: v for d in cfg['peak_lat'] for k, v in d.items()}\n",
    "peak_lat = component_p['peak_lat']\n",
    "\n",
    "# tw_width = {k: v for d in cfg['tw_width'] for k, v in d.items()}\n",
    "tw_width = component_p['tw_width']\n",
    "\n",
    "# Amount of time to shift event codes by, based on empirical testing with photocell\n",
    "#  to determine lag between event code and actual stimulus appearance on screen.\n",
    "#  For reasons that are unclear, we need to double this value (in sec) to get the correct shift\n",
    "tshift = config['t_shift']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228532d",
   "metadata": {},
   "source": [
    "## Define ROIs\n",
    "clusters of electrodes to average over for waveform plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convoluted unpacking from yaml\n",
    "rois_all = {k: v for d in config['rois'] for k, v in d.items()}\n",
    "for roi, chs in rois_all.items():\n",
    "    rois_all[roi]= [c.split(', ') for c in chs][0]\n",
    "\n",
    "rois = {roi:rois_all[roi]  for roi in component_p['rois']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ac49e",
   "metadata": {},
   "source": [
    "## Conditions and Contrasts of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = list(event_id.values())\n",
    "\n",
    "contrasts = {'CS-FF':['ConsonantString', 'FalseFont'],\n",
    "             'RW-FF':['RealWord', 'FalseFont'],\n",
    "             'PW-FF':['PseudoWord', 'FalseFont'],\n",
    "             'NW-FF':['NovelWord', 'FalseFont'],\n",
    "             'RW-CS':['RealWord', 'ConsonantString'],\n",
    "             'PW-CS':['PseudoWord', 'ConsonantString'],\n",
    "             'NW-CS':['NovelWord', 'ConsonantString'],\n",
    "             'RW-PW':['RealWord', 'PseudoWord'],\n",
    "             'RW-NW':['RealWord', 'NovelWord'],\n",
    "             'NW-PW':['NovelWord', 'PseudoWord']\n",
    "             }\n",
    "contr_order = list(contrasts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64169fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1733ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = op.join(bids_root)\n",
    "source_path = op.join(bids_root, 'derivatives', 'erp_preprocessing')\n",
    "\n",
    "data_path = op.join(bids_root, 'derivatives', 'behavioral_demographic', 'data')\n",
    "    \n",
    "derivatives_path = op.join(bids_root, 'derivatives', 'erp_lme', component)\n",
    "if Path(derivatives_path).exists() == False:\n",
    "    Path(derivatives_path).mkdir(parents=True)\n",
    "\n",
    "out_path = op.join(derivatives_path, 'data')\n",
    "if Path(out_path).exists() == False:\n",
    "    Path(out_path).mkdir(parents=True)\n",
    "\n",
    "fig_path = op.join(derivatives_path, 'figures')\n",
    "if Path(fig_path).exists() == False:\n",
    "    Path(fig_path).mkdir(parents=True) \n",
    "    \n",
    "epochs_suffix = '-epo.fif'\n",
    "group_stem = op.join(out_path, 'participants_')\n",
    "scatterplot_stem = op.join(fig_path, 'regr_plot_' + component + '_')\n",
    "swarmplot_stem = op.join(fig_path, 'swarmplot_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca8d5e",
   "metadata": {},
   "source": [
    "## Figure settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('colorblind')\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "colors = {'FalseFont':sns.color_palette('colorblind')[0], \n",
    "          'ConsonantString':sns.color_palette('colorblind')[1], \n",
    "          'PseudoWord':sns.color_palette('colorblind')[2], \n",
    "          'NovelWord':sns.color_palette('colorblind')[3], \n",
    "          'RealWord':sns.color_palette('colorblind')[4]}\n",
    "\n",
    "contr_colors = {'CS-FF':colors['ConsonantString'],\n",
    "                'RW-FF':colors['RealWord'],\n",
    "                'PW-FF':colors['PseudoWord'],\n",
    "                'NW-FF':colors['NovelWord'],\n",
    "                'RW-CS':colors['RealWord'],\n",
    "                'PW-CS':colors['PseudoWord'],\n",
    "                'NW-CS':colors['NovelWord'],\n",
    "                'RW-PW':sns.color_palette('colorblind')[8],\n",
    "                'RW-NW':sns.color_palette('colorblind')[9],\n",
    "                'NW-PW':sns.color_palette('colorblind')[6]\n",
    "                }\n",
    "\n",
    "fig_format = 'pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf84d43",
   "metadata": {},
   "source": [
    "## Subject list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sub-'\n",
    "subjects = sorted([s[-7:] for s in glob(source_path + '/' + prefix + '*')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9badf603",
   "metadata": {},
   "source": [
    "---\n",
    "# Read ERP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b408e",
   "metadata": {},
   "source": [
    "When we read the data, we also crop the epochs as specified above, and time-shift the event onsets to match true stimulus timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = {}\n",
    "for subject in subjects:\n",
    "    subj_path = op.join(source_path, subject, 'eeg')\n",
    "    epochs[subject] = mne.read_epochs(str(subj_path + '/' + subject + '_task-' + task + epochs_suffix),\n",
    "                                         verbose=None, \n",
    "                                         preload=True)\n",
    "    # correct for stimulus presentation delay\n",
    "    epochs[subject]._raw_times = epochs[subject]._raw_times - tshift\n",
    "    epochs[subject]._times_readonly = epochs[subject]._times_readonly - tshift\n",
    "    \n",
    "    epochs[subject].crop(tmin=t_min, tmax=t_max).apply_baseline(baseline)\n",
    "    \n",
    "    epochs[subject].set_montage(montage_fname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bc9719e",
   "metadata": {},
   "source": [
    "---\n",
    "# Compute single-trial measurements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for subj in subjects:\n",
    "    for cond in conditions:\n",
    "        for roi, chans in rois_all.items():                \n",
    "            if component_meas == 'meana':\n",
    "                peak = np.array([np.nan, \n",
    "                                 np.median([component_p['tw_range'][0], \n",
    "                                            component_p['tw_range'][1]]\n",
    "                                          ), \n",
    "                                 np.nan])\n",
    "            else:\n",
    "                # find peak amplitude in specified timewindow, among channels in ROI(s) of interest\n",
    "                tmp_dat = epochs[subj][cond].average().pick_channels(chans)\n",
    "                peak = tmp_dat.get_peak(tmin=component_p['tw_range'][0],\n",
    "                                        tmax=component_p['tw_range'][1], \n",
    "                                        mode=component_p['component_meas'],\n",
    "                                       )  \n",
    "\n",
    "            # define time window for averaging, centred on peak\n",
    "            peak_window = ((peak[1] - (component_p['tw_width'] / 2)), \n",
    "                           (peak[1] + (component_p['tw_width'] / 2)))\n",
    "            idx_start, idx_stop = np.searchsorted(epochs[subj][cond].times, peak_window)\n",
    "\n",
    "            # Get individual trial measurements centred on print tuning peak\n",
    "            df_list.append(pd.concat([pd.DataFrame({'participant_id': subj, \n",
    "                                                   'Component':component,\n",
    "                                                   'Trial_Time':np.repeat(epochs[subj][cond].events[:,0], len(chans)),\n",
    "                                                   'Condition':cond,\n",
    "                                                    'ROI':roi,\n",
    "                                                    'Peak.Chan':peak[0],\n",
    "                                                    'Peak.Lat':peak[1],\n",
    "                                                   'Channel':np.tile(chans, epochs[subj][cond].selection.shape),\n",
    "                                                   }),\n",
    "                                    pd.DataFrame(epochs[subj][cond].copy().get_data(picks=chans)[:, :, idx_start:idx_stop].mean(axis=-1).flatten() * 10e5,\n",
    "                                                 columns=['Amplitude']), \n",
    "                                    ], axis=1))\n",
    "\n",
    "# concatenate list of dataframes, and add x,y,z coordinates of channels                \n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc132f1",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "Remove individual data points <> 2 SD. Compute separately for each subject and component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fafa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_thresh = config['outlier_thresh'] # cutoff for defining outliers, in SD\n",
    "\n",
    "# Compute standard (z) scores \n",
    "df['Peak.Ampl.z'] = df.loc[:, ['participant_id', \n",
    "                               'Component', \n",
    "                               'Amplitude']].groupby(['participant_id', \n",
    "                                                      'Component']).transform(zscore)\n",
    "\n",
    "len_orig = len(df)\n",
    "\n",
    "# Drop outliers based on z_thresh\n",
    "df = df[(df['Peak.Ampl.z'] >= -z_thresh) & (df['Peak.Ampl.z'] <= z_thresh)]\n",
    "\n",
    "n_dropped = len_orig - len(df)\n",
    "print(str(round(((n_dropped / len_orig) * 100), 3)) + '% of data dropped as outliers based Peak.Amplitude z +/-' + str(z_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d9514",
   "metadata": {},
   "source": [
    "---\n",
    "## Aggregate over trials and channels, within subjects and conditions\n",
    "- To ensure proper CIs (between-subject variance) in plots below.\n",
    "- Also select only ROIOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c86a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df[df['ROI'].isin(rois)].groupby(['participant_id', 'Component', 'Condition', 'ROI'])['Amplitude'].mean().reset_index()\n",
    "\n",
    "# write to file\n",
    "feather.write_feather(df_agg, group_stem + 'trialavg.feather')\n",
    "df_agg.sample(12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c96d8f92",
   "metadata": {},
   "source": [
    "## Read demographic & standardized test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61bc540c",
   "metadata": {},
   "source": [
    "### Need to rename rt and acc columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB = pd.concat([pd.read_csv(op.join(raw_path, 'participants.tsv'), sep='\\t', index_col=0), \n",
    "                pd.read_csv(op.join(raw_path, 'participants_std_tests.tsv'), sep='\\t', index_col=0),\n",
    "                pd.read_csv(op.join(data_path, 'ldt_acc_by_subj_wide.tsv'), sep='\\t', index_col=0, \n",
    "            header=0, names=['acc_CNST', 'acc_FFNT', 'acc_NVWD', 'acc_PSWD', 'acc_RLWD']),\n",
    "                pd.read_csv(op.join(data_path, 'ldt_rt_trimmed_by_subj_wide.tsv'), sep='\\t', index_col=0, \n",
    "            header=0, names=['rt_CNST', 'rt_FFNT', 'rt_NVWD', 'rt_PSWD', 'rt_RLWD']),\n",
    "                pd.read_csv(op.join(data_path, 'ldt_sdt_data.tsv'), sep='\\t', index_col=0)\n",
    "                ],\n",
    "                axis=1)           \n",
    "\n",
    "dfB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = df_agg.join(dfB, on='participant_id', how='outer')\n",
    "\n",
    "dfA.sample(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a938142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105f690",
   "metadata": {},
   "source": [
    "## Plot relationships between ERP component amplitude and behavioural measures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a88ed84e",
   "metadata": {},
   "source": [
    "### Novel Word accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9eabf-814c-461d-93c3-74b6cf0ee1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_var = 'Ortho_Choice'\n",
    "ax = sns.lmplot(data=dfA,\n",
    "              x=beh_var, y=\"Amplitude\", \n",
    "              col='ROI', row='Condition', row_order=conditions,\n",
    "              ci=95,\n",
    "            scatter_kws={'s': 33}\n",
    "             )\n",
    "\n",
    "ax.savefig(scatterplot_stem + beh_var + '.' + fig_format)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9eabf-814c-461d-93c3-74b6cf0ee1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "beh_var = 'acc_NVWD'\n",
    "ax = sns.lmplot(data=dfA,\n",
    "              x=beh_var, y=\"Amplitude\", \n",
    "              col='ROI', hue='Condition', hue_order=conditions,\n",
    "              ci=95,\n",
    "            scatter_kws={'s': 33}\n",
    "             )\n",
    "# ax.set(ylim=(-17, 0))\n",
    "\n",
    "ax.savefig(scatterplot_stem + beh_var + '_combined.' + fig_format)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f73a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "760055932674735d287fd612619c18ffc3840c7c49c197eeb438d57975a1e213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
